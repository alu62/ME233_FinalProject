{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Automated Model Discovery for RTV-2 Silicone Rubber\n",
        "\n",
        "Model Discovery Papers:\n",
        "1. Invariant-based: https://www.sciencedirect.com/science/article/pii/S1742706123000661\n",
        "2. Principal-stretch-based: https://www.sciencedirect.com/science/article/pii/S2666522023000047\n",
        "\n",
        "Brain Data Reference: https://www.sciencedirect.com/science/article/pii/S1742706116305633\n",
        "\n",
        "Code by Skyler St. Pierre & Kevin Linka \\\\\n",
        "Last edited February 2025\n",
        "\n",
        "Code Modified by Alexander Lu, Nachuan You, Ruitao Su, Yixiang Guo \\\\\n",
        "Last edited March 2025"
      ],
      "metadata": {
        "id": "Se438kR0HIri"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Problem description\n",
        "\n",
        "A hyperelastic or Green-elastic materials with can directly be defined by the Piola stress\n",
        "$$\n",
        "  \\mathbf{P}\n",
        "= \\frac{\\partial \\psi (\\mathbf{F})}{\\partial \\mathbf{F}} \\,,\n",
        "$$\n",
        "in dependency of the strain energy function $\\Psi$ and the deforation gradient $\\mathbf{F}$. Now, by contraining the material symmetry to the special case of isotropy, the strain energy function can be given as a function of the first three strain invariants as $\\Psi(I_1, \\, I_2,\\, I_3)$\n",
        "\n",
        "\n",
        "We can further constrain the choice of the free energy function $\\psi$ for the special case of perfect incompressibility for which the Jacobian remains constant and equal to one, $I_3 = 1$. So we obtain for the Piola stress tensor\n",
        "$$\n",
        "  \\mathbf{P}\n",
        "= \\frac{\\partial \\psi}{\\partial I_1} \\frac{\\partial I_1}{\\partial \\mathbf{F}}\n",
        "+ \\frac{\\partial \\psi}{\\partial I_2} \\frac{\\partial I_2}{\\partial \\mathbf{F}}\n",
        "- p\\, \\mathbf{F}^{\\rm {-t}}  \n",
        "~~~~~=~~~~~ 2 \\left[\\frac{\\partial \\psi}{\\partial I_1}\n",
        "   + I_1 \\frac{\\partial \\psi}{\\partial I_2} \\right] \\mathbf{F}\n",
        "-2 \\frac{\\partial \\psi}{\\partial I_2}\n",
        "   \\mathbf{F} \\cdot \\mathbf{F}^{\\rm {t}} \\cdot \\mathbf{F}\n",
        "- p\\, \\mathbf{F}^{\\rm {-t}} \\, .     \n",
        "$$\n",
        "\n",
        "This implies that we reduce the input to a set of only two invariants, $I_1$ and $I_2$ as functional basis of the strain energy we want to obtain.\n",
        "\n",
        "\n",
        "Before we start with discovering the strain energy function, dependent on the first two invariants, we have to initialize all necessary python pckages and load the brain data.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "### 0. Load python packages"
      ],
      "metadata": {
        "id": "Lc5wZXS329As"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# # the current colab versions are not compatible with this notebook so we need to install these older package versions\n",
        "!pip install matplotlib==3.2.2\n",
        "!pip install tensorflow==2.12.0\n",
        "!pip install numpy==1.23.5\n",
        "!pip install pandas==1.5.3\n",
        "# do not restart the runtime until all packages have been installed (hit cancel on the pop-up)!!\n",
        "# the errors in red that print out can be ignored; they will not affect this code"
      ],
      "metadata": {
        "id": "7ODWLtwLAQQD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Select `Runtime` > `Restart Session` at the top of the file before running the next code block!**"
      ],
      "metadata": {
        "id": "Difswvx5cCL4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "koxfCXBQn_9g"
      },
      "outputs": [],
      "source": [
        "# import necessary python packages\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.gridspec as gridspec\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import tensorflow.keras as keras\n",
        "import tensorflow.keras.backend as K\n",
        "import json\n",
        "import pandas as pd\n",
        "import os\n",
        "import copy\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "\n",
        "\n",
        "# Check Versions\n",
        "print('Numpy: ' + np.__version__) # 1.23.5\n",
        "print('Matplotlib: ' + matplotlib.__version__) # 3.2.2\n",
        "print('Tensorflow: ' + tf.__version__) # 2.12.0\n",
        "print('Keras: ' + keras.__version__)\n",
        "print('Pandas: ' + pd.__version__) # 1.5.3"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Import excel file, change to match where you saved the file\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "path = '/content/drive/MyDrive/Colab Notebooks/PROJECT/' # change to where you download this; must be in Google Drive\n",
        "#path = '/content/drive/MyDrive/PROJECT/'\n",
        "dfs = pd.read_excel(path + 'elastosil7683_truncated.xlsx', sheet_name='Sheet1')"
      ],
      "metadata": {
        "id": "rGsjGLS7zi5A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Make path to save results to\n",
        "def makeDIR(path):\n",
        "    if not os.path.exists(path):\n",
        "        os.makedirs(path)\n",
        "\n",
        "filename = 'elastosil7683' # Change to keep track of different data e.g. Brain, Skin, Muscle, etc.\n",
        "# path2saveRaw = path + 'Results/'+filename+'/RawData'\n",
        "# makeDIR(path2saveRaw)"
      ],
      "metadata": {
        "id": "7sfy33YSiNQh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Load Brain data"
      ],
      "metadata": {
        "id": "FuvDD-UW3UIa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load data for different brain regions\n",
        "def getStressStrain(Region):\n",
        "\n",
        "    if Region =='CX':\n",
        "        P_ut = dfs.iloc[1:,1].dropna().astype(np.float64)\n",
        "        lam_ut = dfs.iloc[1:,0].dropna().astype(np.float64)\n",
        "\n",
        "        # P_ss = dfs.iloc[3:,3].dropna().astype(np.float64).values\n",
        "    #     # gamma_ss = dfs.iloc[3:,2].dropna().astype(np.float64).values\n",
        "    # elif Region =='CR':\n",
        "    #     P_ut = dfs.iloc[3:,6].dropna().astype(np.float64)\n",
        "    #     lam_ut = dfs.iloc[3:,5].dropna().astype(np.float64)\n",
        "\n",
        "    #     P_ss = dfs.iloc[3:,8].dropna().astype(np.float64).values\n",
        "    #     gamma_ss = dfs.iloc[3:,7].dropna().astype(np.float64).values\n",
        "    # elif Region =='BG':\n",
        "    #     P_ut = dfs.iloc[3:,11].dropna().astype(np.float64)\n",
        "    #     lam_ut = dfs.iloc[3:,10].dropna().astype(np.float64)\n",
        "\n",
        "    #     P_ss = dfs.iloc[3:,13].dropna().astype(np.float64).values\n",
        "    #     gamma_ss = dfs.iloc[3:,12].dropna().astype(np.float64).values\n",
        "    # elif Region =='CC':\n",
        "    #     P_ut = dfs.iloc[3:,16].dropna().astype(np.float64)\n",
        "    #     lam_ut = dfs.iloc[3:,15].dropna().astype(np.float64)\n",
        "\n",
        "    #     P_ss = dfs.iloc[3:,18].dropna().astype(np.float64).values\n",
        "    #     gamma_ss = dfs.iloc[3:,17].dropna().astype(np.float64).values\n",
        "\n",
        "    return P_ut, lam_ut\n",
        "\n",
        "# Define different loading protocols\n",
        "def traindata(modelFit_mode):\n",
        "    if modelFit_mode == 'T':\n",
        "        model_given = model_UT\n",
        "        input_train = lam_ut[:3239]\n",
        "        output_train = P_ut[:3239]\n",
        "        sample_weights = np.array([1.0]*input_train.shape[0])\n",
        "\n",
        "    # elif modelFit_mode == \"C\":\n",
        "    #     model_given = model_UT\n",
        "    #     input_train = lam_ut[:17]\n",
        "    #     output_train = P_ut[:17]\n",
        "    #     sample_weights = np.array([1.0]*input_train.shape[0])\n",
        "\n",
        "    # elif modelFit_mode == \"SS\":\n",
        "    #     model_given = model_SS\n",
        "    #     input_train = gamma_ss\n",
        "    #     output_train = P_ss\n",
        "    #     sample_weights = np.array([1.0]*input_train.shape[0])\n",
        "\n",
        "    # elif modelFit_mode == \"TC_and_SS\":\n",
        "    #     model_given = model\n",
        "    #     input_train = [[lam_ut], [gamma_ss]]\n",
        "    #     output_train = [[P_ut], [P_ss]]\n",
        "    #     # normalize each Ten, Com, Shr by respective max absolute stress\n",
        "    #     sample_weights_tc = np.array([1.0] * lam_ut.shape[0])\n",
        "    #     sample_weights_tc[16:] = 1 / np.max(np.abs(P_ut[16:]))  # weight by max tension\n",
        "    #     sample_weights_tc[:16] = 1 / np.max(np.abs(P_ut[:16]))  # weight by max compression\n",
        "    #     sample_weights_ss = np.array([1.0] * gamma_ss.shape[0]) / np.max(np.abs(P_ss))  # weight by max shear\n",
        "    #     sample_weights = [[sample_weights_tc], [sample_weights_ss]]\n",
        "    return model_given, input_train, output_train, sample_weights"
      ],
      "metadata": {
        "id": "O6IYNvlxqvQQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Select region to investigate: CX = cortex, CC = corpus callosum, BG = basal ganglia, CR = corona radiata\n",
        "Region_test = 'CX'  # corpus callosum\n",
        "P_ut, lam_ut = getStressStrain(Region_test)\n"
      ],
      "metadata": {
        "id": "EAbFs9LqeX9v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# HW Problem 2.1a: Plot tension and compression\n",
        "plt.figure(figsize=(12.5,8.33))\n",
        "plt.plot(stretch,stress,color='blue')\n",
        "plt.plot(np.linspace(0.9, 1.1, 100), np.linspace(0,0,100),'k')\n",
        "plt.plot(np.linspace(1, 1, 100), np.linspace(-0.5,0.1,100),'k')\n",
        "plt.xlabel('Stretch')\n",
        "plt.ylabel('Stress')\n",
        "plt.title('corpus callosum: compression & tension')\n",
        "plt.tight_layout(pad=2)\n",
        "plt.savefig(path2saveRaw + '/' + Region_test + '_TenCom' + '.pdf')"
      ],
      "metadata": {
        "id": "1Nkb1_SPeLQ6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### L1 and L2 regularization with penalty weight\n",
        "\n"
      ],
      "metadata": {
        "id": "Qdsxsk3V1cZp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def regularize(reg, pen):\n",
        "    if reg == 'L2':\n",
        "        return keras.regularizers.l2(pen)\n",
        "    if reg == 'L1':\n",
        "        return keras.regularizers.l1(pen)"
      ],
      "metadata": {
        "id": "aDqcHT6r1a8J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2b. Strain Energy Model - Principal-stretch-based\n",
        "\n",
        "\n",
        "Next, we define the strain energy function for our isotropic, perfectly incompressible Constitutive Artificial Neural Network with one hidden layers and twenty nodes using the principal stretches.\n",
        "The set of equations for this network takes the following explicit form,\n",
        "\n",
        "\n",
        "$$ \\begin{array}{l@{\\hspace*{0.05cm}}r@{\\hspace*{0.05cm}}\n",
        "              l@{\\hspace*{0.05cm}}l@{\\hspace*{0.00cm}}\n",
        "              c@{\\hspace*{0.05cm}}c@{\\hspace*{0.05cm}}\n",
        "              l@{\\hspace*{0.05cm}}l@{\\hspace*{0.00cm}}\n",
        "              l@{\\hspace*{0.05cm}}c@{\\hspace*{0.05cm}}\n",
        "              l@{\\hspace*{0.05cm}}l@{\\hspace*{0.00cm}}l}\n",
        "   \\psi\n",
        "&= \\sum_{i=1}^3 &\n",
        "    w_1   &[\\lambda_i^{-30}&-1]\n",
        "&+& w_2   &[\\lambda_i^{-28}&-1]\n",
        "&+& w_3   &[\\lambda_i^{-26}&-1] \\\\\n",
        "&+& w_4   &[\\lambda_i^{-24}&-1]\n",
        "&+& w_5   &[\\lambda_i^{-22}&-1]  \n",
        "&+& w_6   &[\\lambda_i^{-20}&-1] \\\\\n",
        "&+& w_7   &[\\lambda_i^{-18}&-1]\n",
        "&+& w_8   &[\\lambda_i^{-16}&-1]\n",
        "&+& w_9   &[\\lambda_i^{-14}&-1]  \\\\\n",
        "&+& w_{10}&[\\lambda_i^{-12}&-1]\n",
        "&+& w_{11}&[\\lambda_i^{-10}&-1]\n",
        "&+& w_{12}&[\\lambda_i^{-8}&-1] \\\\\n",
        "&+& w_{13}&[\\lambda_i^{-6}&-1]\n",
        "&+& w_{14}&[\\lambda_i^{-4}&-1]\n",
        "&+& w_{15}&[\\lambda_i^{-2}&-1] \\\\\n",
        "&+& w_{16}&[\\lambda_i^{+2}&-1]\n",
        "&+& w_{17}&[\\lambda_i^{+4}&-1]\n",
        "&+& w_{18}&[\\lambda_i^{+6}&-1] \\\\\n",
        "&+& w_{19}&[\\lambda_i^{+8}&-1]\n",
        "&+& w_{20}&[\\lambda_i^{+10}&-1]&\n",
        "\\end{array}\n",
        "$$"
      ],
      "metadata": {
        "id": "Sa1ZyAC53m0S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "initializer_exp = tf.keras.initializers.RandomUniform(minval=0., maxval=0.001, seed=np.random.randint(0,10000)) # use random integer as seed\n",
        "initializer_1 = 'glorot_normal'\n",
        "\n",
        "# Self defined activation functions for exp term\n",
        "def activation_Exp(x):\n",
        "    return 1.0*(tf.math.exp(x) -1.0)\n",
        "# Self defined activation functions for ln term\n",
        "def activation_ln(x):\n",
        "    return -1.0*tf.math.log(1.0 - (x))\n",
        "\n",
        "\n",
        "def princStretch(inputs): # convert invariants to principal stretches\n",
        "    (I1_in, I2_in) = inputs\n",
        "    Stretch_1_0 = 1.0\n",
        "\n",
        "    Q = (tf.math.pow(I1_in, 2) - 3.0 * I2_in) + 0.001\n",
        "    R = ((-9.0 * I1_in * I2_in) + 27.0 + (2.0 * tf.math.pow(I1_in, 3)))\n",
        "    Theta = tf.math.acos(R / (2.0 * tf.math.pow(Q, 3 / 2)))\n",
        "\n",
        "    Stretch_1 = 1.0 / 3.0 * (\n",
        "                I1_in + 2.0 * tf.math.sqrt(Q) * tf.math.cos(1.0 / 3.0 * (Theta + 2.0 * np.pi * (1.0 - 1.0))))\n",
        "    Stretch_2 = 1.0 / 3.0 * (\n",
        "                I1_in + 2.0 * tf.math.sqrt(Q) * tf.math.cos(1.0 / 3.0 * (Theta + 2.0 * np.pi * (2.0 - 1.0))))\n",
        "    Stretch_3 = 1.0 / 3.0 * (\n",
        "                I1_in + 2.0 * tf.math.sqrt(Q) * tf.math.cos(1.0 / 3.0 * (Theta + 2.0 * np.pi * (3.0 - 1.0))))\n",
        "\n",
        "    return tf.math.sqrt(Stretch_1), tf.math.sqrt(Stretch_2), tf.math.sqrt(Stretch_3), Q\n",
        "\n",
        "\n",
        "def SingleInvImproved(I1_ref, reg, pen):\n",
        "\n",
        "    I_1_w1 = keras.layers.Dense(\n",
        "        1,\n",
        "        kernel_initializer=initializer_1,\n",
        "        kernel_constraint=keras.constraints.NonNeg(),\n",
        "        kernel_regularizer=regularize(reg, pen),\n",
        "        use_bias=False,\n",
        "        activation=None,\n",
        "        # name=f'w_{counter}_1'\n",
        "    )(I1_ref)\n",
        "\n",
        "    I_1_w2 = keras.layers.Dense(\n",
        "        1,\n",
        "        kernel_initializer=initializer_exp,\n",
        "        kernel_constraint=keras.constraints.NonNeg(),\n",
        "        kernel_regularizer=regularize(reg, pen),\n",
        "        use_bias=False,\n",
        "        activation=activation_Exp,\n",
        "        # name=f'w_{counter}_2'\n",
        "    )(I1_ref)\n",
        "\n",
        "    collect_out = tf.keras.layers.concatenate([I_1_w1, I_1_w2], axis=1)\n",
        "\n",
        "    return collect_out\n",
        "\n",
        "def StrainEnergyCANN_stretch(reg, pen):\n",
        "    # Inputs defined\n",
        "    I1_in = tf.keras.Input(shape=(1,), name='I1')\n",
        "    I2_in = tf.keras.Input(shape=(1,), name='I2')\n",
        "    # Get principal stretches\n",
        "    Stretch_1, Stretch_2, Stretch_3, Q = keras.layers.Lambda(\n",
        "        function=princStretch,\n",
        "        name='P_stretch'\n",
        "    )([I1_in, I2_in])\n",
        "\n",
        "    ALL_I_out_arr = []\n",
        "    counter = 0  # Unique index for naming\n",
        "    for i in range(-8, 10, 2):  # define range of exponential powers and number of terms\n",
        "        if i != 0:\n",
        "            I1_out = SingleInvImproved(Stretch_1 ** i + Stretch_2 ** i + Stretch_3 ** i - 3.0, reg, pen)\n",
        "            ALL_I_out_arr.append(I1_out)\n",
        "            counter += 1\n",
        "\n",
        "    ALL_I_out = tf.keras.layers.concatenate(ALL_I_out_arr, axis=1)\n",
        "    amount_terms = len(ALL_I_out_arr)\n",
        "\n",
        "    W_ANN = keras.layers.Dense(\n",
        "        1,\n",
        "        kernel_initializer='glorot_normal',\n",
        "        kernel_constraint=keras.constraints.NonNeg(),\n",
        "        kernel_regularizer=regularize(reg, pen),\n",
        "        use_bias=False,\n",
        "        activation=None,\n",
        "        name='wx2'\n",
        "    )(ALL_I_out)\n",
        "\n",
        "    Psi_model = keras.models.Model(inputs=[I1_in, I2_in], outputs=[W_ANN], name='Psi')\n",
        "    return Psi_model, amount_terms*2\n",
        "\n"
      ],
      "metadata": {
        "id": "-zRIhzsI3kGD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Stress Models\n",
        "\n",
        "\n",
        "####  Tension and compression\n",
        "\n",
        "For the case of uniaxial tension and compression, we stretch the specimen in one direction,\n",
        "$F_{11} = \\lambda_1 = \\lambda$.\n",
        "For an isotropic, perfectly incompressible material with\n",
        "$I_3 = \\lambda_1^2  \\lambda_2^2  \\lambda_3^2 = 1$,\n",
        "the stretches orthogonal to the loading direction are identical and equal to the square root of the stretch,\n",
        "$F_{22} = \\lambda_2 = \\lambda^{-1/2}$ and\n",
        "$F_{33} = \\lambda_3 = \\lambda^{-1/2}$.\n",
        "From the resulting deformation gradient,\n",
        "$F= {\\rm{diag}} \\, \\{ \\; \\lambda, \\lambda^{-1/2}, \\lambda^{-1/2} \\,\\}$,\n",
        "we calculate the first and second invariants and their derivatives,\n",
        "\n",
        "$$\n",
        "  I_1\n",
        "= \\lambda^2 + \\frac{2}{\\lambda}\n",
        "  \\quad \\mbox{and} \\quad\n",
        "  I_2\n",
        "= 2\\lambda + \\frac{1}{\\lambda^2}\n",
        "  \\quad \\mbox{with} \\quad\n",
        "  \\frac{\\partial I_1}{\\partial  \\lambda}\n",
        "= 2 \\, \\left[\\lambda - \\frac{1}{\\lambda^2} \\right]\n",
        "  \\quad \\mbox{and} \\quad\n",
        "  \\frac{\\partial I_2}{\\partial  \\lambda}\n",
        "= 2 \\, \\left[1 - \\frac{1}{\\lambda^3}\\right] \\,,\n",
        "$$\n",
        "\n",
        "to evaluate the nominal uniaxial stress $P_{11}$\n",
        "using the general stress-stretch relationship for perfectly incompressible materials,\n",
        "$ P_{ii}\n",
        "= [{\\partial \\psi}/{\\partial I_1}] \\,\n",
        "  [{\\partial I_1} /{\\partial \\lambda_i}]\n",
        "+ [{\\partial \\psi}/{\\partial I_2}] \\,\n",
        "  [{\\partial I_2} /{\\partial \\lambda_i}]\n",
        "- [{1}/{\\lambda_i}] \\, p $,\n",
        "for $i = 1,2,3$.\n",
        "Here, $p$ denotes the hydrostatic pressure that we determine from the zero stress condition in the transverse directions, $P_{22} = 0$ and $P_{33} = 0$, as\n",
        "$ p\n",
        "= [{2}/{\\lambda}] \\;\n",
        "  {\\partial \\psi}/{\\partial I_1}\n",
        "+ [2\\lambda+{2}/{\\lambda^2}] \\,\n",
        "  {\\partial \\psi}/{\\partial I_2}$.\n",
        "This results in the following explicit uniaxial stress-stretch relation for perfectly incompressible, isotropic materials,\n",
        "\n",
        "$$\n",
        "  P_{11}\n",
        "= 2 \\,\n",
        "  \\left[\n",
        "  \\frac{\\partial \\psi}{\\partial I_1}\n",
        "+ \\frac{1}{\\lambda}\n",
        "  \\frac{\\partial \\psi}{\\partial I_2}\n",
        "  \\right]\n",
        "  \\left[\n",
        "  \\lambda - \\frac{1}{\\lambda^2}\n",
        "  \\right]\\,.\n",
        "$$\n"
      ],
      "metadata": {
        "id": "tm8k_7Ve3yAb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def Stress_calc_TC(inputs):\n",
        "    (dPsidI1, dPsidI2, Stretch) = inputs\n",
        "    one = tf.constant(1.0,dtype='float32')\n",
        "    two = tf.constant(2.0,dtype='float32')\n",
        "    minus  = two * (dPsidI1 *  one/ K.square(Stretch)  + dPsidI2 * one/K.pow(Stretch,3))\n",
        "    stress = two * (dPsidI1 *  Stretch + dPsidI2 * one) - minus\n",
        "\n",
        "    return stress"
      ],
      "metadata": {
        "id": "SUj9Kf5y3vAQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####  Shear\n",
        "\n",
        "For the case of simple shear, we shear the specimen in one direction, $F_{12} = \\gamma$.\n",
        "For an isotropic, perfectly incompressible material with\n",
        "$F_{11} = F_{22} = F_{33} = 1$,\n",
        "we calculate the first and second invariants and their derivatives,\n",
        "$$\n",
        "  I_1\n",
        "= 3 + \\gamma^2\n",
        "  \\quad \\mbox{and} \\quad\n",
        "  I_2\n",
        "= 3 + \\gamma^2\n",
        "  \\quad \\mbox{with} \\quad\n",
        "  \\frac{\\partial I_1}{\\partial  \\lambda}\n",
        "= 2 \\, \\gamma\n",
        "  \\quad \\mbox{and} \\quad\n",
        "  \\frac{\\partial I_2}{\\partial  \\lambda}\n",
        "= 2 \\, \\gamma \\,,\n",
        "$$\n",
        "to evalute the nominal shear stress $P_{12}$\n",
        "using the general stress-stretch relationship for perfectly incompressible materials.\n",
        "This results in the following explicit shear stress-strain relation for perfectly incompressible, isotropic materials,\n",
        "$$\n",
        "  P_{12}\n",
        "= 2\\,\n",
        "  \\left[\n",
        "  \\frac{\\partial \\psi}{\\partial I_1}\n",
        "+ \\frac{\\partial \\psi}{\\partial I_2}\n",
        "  \\right]\n",
        "  \\gamma\\,.\n",
        "$$\n"
      ],
      "metadata": {
        "id": "RY2kbH8d357e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Simple shear stress P12\n",
        "def Stress_cal_SS(inputs):\n",
        "    (dPsidI1, dPsidI2, gamma) = inputs\n",
        "    two = tf.constant(2.0,dtype='float32')\n",
        "    stress = two * gamma * (dPsidI1  + dPsidI2)\n",
        "\n",
        "    return stress"
      ],
      "metadata": {
        "id": "MGn1dKZ134rS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finally, we can define seperate stress models for tension/compression, shear and a combination of all loading states."
      ],
      "metadata": {
        "id": "eTwDkRFm4BWf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Gradient function\n",
        "def myGradient(a, b):\n",
        "    der = tf.gradients(a, b, unconnected_gradients='zero')\n",
        "    return der[0]\n",
        "\n",
        "def modelArchitecture(Psi_model):\n",
        "    # Stretch and Gamma as input\n",
        "    Stretch = keras.layers.Input(shape = (1,),\n",
        "                                  name = 'Stretch')\n",
        "    # Gamma = keras.layers.Input(shape = (1,),\n",
        "                                  # name = 'gamma')\n",
        "\n",
        "    # specific Invariants UT\n",
        "    I1_UT = keras.layers.Lambda(lambda x: x**2   + 2.0/x  )(Stretch)\n",
        "    I2_UT = keras.layers.Lambda(lambda x: 2.0*x  + 1/x**2 )(Stretch)\n",
        "\n",
        "    #% load specific models\n",
        "    Psi_UT = Psi_model([I1_UT, I2_UT])\n",
        "\n",
        "    # derivative UT\n",
        "    dWI1_UT  = keras.layers.Lambda(lambda x: myGradient(x[0], x[1]))([Psi_UT, I1_UT])\n",
        "    dWdI2_UT = keras.layers.Lambda(lambda x: myGradient(x[0], x[1]))([Psi_UT, I2_UT])\n",
        "\n",
        "    # Stress UT\n",
        "    Stress_UT = keras.layers.Lambda(function = Stress_calc_TC,\n",
        "                                name = 'Stress_UT')([dWI1_UT,dWdI2_UT,Stretch])\n",
        "\n",
        "    # Define model for different load case\n",
        "    model_UT = keras.models.Model(inputs=Stretch, outputs= Stress_UT)\n",
        "    # Combined model\n",
        "    model = keras.models.Model(inputs=[model_UT.inputs], outputs=[model_UT.outputs])\n",
        "\n",
        "    return model_UT, Psi_model, model\n"
      ],
      "metadata": {
        "id": "ZLlSaN-P4EHU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. Compile model\n",
        "\n",
        "The compiler definition comprises the loss function definition (here a mean squared error metric), the optimizer (here an Adam optimizer) and the evaluation metric (also mean squared error).\n",
        "\n",
        "Moreover, we define model callbacks and the keras fit function. The latter obtains the information about which model we want to fit with which data."
      ],
      "metadata": {
        "id": "saYHO1e24JMm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Optimization utilities\n",
        "def Compile_and_fit(model_given, input_train, output_train, epochs, path_checkpoint, sample_weights):\n",
        "\n",
        "    mse_loss = keras.losses.MeanSquaredError()\n",
        "    metrics  =[keras.metrics.MeanSquaredError()]\n",
        "    opti1    = tf.optimizers.Adam(learning_rate=0.001)\n",
        "\n",
        "    model_given.compile(loss=mse_loss,\n",
        "                  optimizer=opti1,\n",
        "                  metrics=metrics)\n",
        "\n",
        "    # if training loss starts to increase, stop training after 3000 additional epochs = \"patience\"\n",
        "    es_callback = keras.callbacks.EarlyStopping(monitor=\"loss\", min_delta=0, patience=100, restore_best_weights=True)\n",
        "\n",
        "    modelckpt_callback = keras.callbacks.ModelCheckpoint(\n",
        "    monitor=\"loss\",\n",
        "    filepath=path_checkpoint,\n",
        "    verbose=0,\n",
        "    save_weights_only=True,\n",
        "    save_best_only=True, # save only the best weights across all epochs\n",
        "    )\n",
        "\n",
        "\n",
        "    history = model_given.fit(input_train,\n",
        "                        output_train,\n",
        "                        batch_size=batch_size,\n",
        "                        epochs=epochs,\n",
        "                        validation_split=0.0,\n",
        "                        callbacks=[es_callback, modelckpt_callback], # save best weights if stop early or go through all epochs\n",
        "                        shuffle = True,\n",
        "                        verbose = 0, # verbose = 2 will print loss each epoch\n",
        "                        sample_weight = sample_weights)\n",
        "\n",
        "    return model_given, history\n"
      ],
      "metadata": {
        "id": "NmCtDWke4J5Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5. Plot functions\n",
        "\n",
        "Here we define some plot functions to be used to plot the results later on"
      ],
      "metadata": {
        "id": "ZwHIjb4g4Pni"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plotLoss(axe, history):\n",
        "    axe.plot(history)\n",
        "    axe.set_yscale('log')\n",
        "    plt.title('model loss')\n",
        "    plt.ylabel('loss')\n",
        "    plt.xlabel('epoch')"
      ],
      "metadata": {
        "id": "5yT9Nfkj4QaD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# plot the contribution of each term to the model stress prediction\n",
        "\n",
        "def color_map(ax, stretch, model, model_weights, Psi_model, cmaplist, terms, model_type):\n",
        "    predictions = np.zeros([stretch.shape[0], terms])\n",
        "    model_plot = copy.deepcopy(model_weights)  # deep copy model weights\n",
        "\n",
        "\n",
        "    for i in range(terms):\n",
        "        if model_type == 'Invariant':\n",
        "            model_plot = np.zeros_like(model_weights)  # wx1 all set to zero\n",
        "            model_plot[i] = model_weights[i]  # wx1[i] set to trained value\n",
        "        else:  # for architectures with multiple layers (invariant)\n",
        "            model_plot[-1] = np.zeros_like(model_weights[-1])  # wx2 all set to zero\n",
        "            model_plot[-1][i] = model_weights[-1][i]  # wx2[i] set to trained value\n",
        "\n",
        "        Psi_model.set_weights(model_plot)\n",
        "        lower = np.sum(predictions, axis=1)\n",
        "        upper = lower + model.predict(stretch, verbose=0)[:].flatten()\n",
        "        predictions[:, i] = model.predict(stretch, verbose=0)[:].flatten()\n",
        "        ax.fill_between(stretch[:], lower.flatten(), upper.flatten(), lw=0, zorder=i + 1, color=cmaplist[i],\n",
        "                         label=i + 1)\n",
        "        # if i == 0:  # one or two term models, get the correct color\n",
        "        #     ax.fill_between(stretch[:], lower.flatten(), upper.flatten(), lw=0, zorder=i + 1, color=cmaplist[0],\n",
        "        #                      label=i + 1)\n",
        "        # else:\n",
        "        #     ax.fill_between(stretch[:], lower.flatten(), upper.flatten(), lw=0, zorder=i + 1, color=cmaplist[7],\n",
        "        #                      label=i + 1)\n",
        "        ax.plot(stretch, upper, lw=0.4, zorder=34, color='k')\n",
        "\n"
      ],
      "metadata": {
        "id": "iOYoQXHk4XfL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.rcParams['xtick.major.pad'] = 14 # set plotting parameters\n",
        "plt.rcParams['ytick.major.pad'] = 14\n",
        "\n",
        "# plot tension, compression, and shear brain data with color maps\n",
        "\n",
        "def plotMapTen(ax, Psi_model, model_weights, model_UT, terms, lam_ut, P_ut, Region, path2saveResults, modelFit_mode, model_type):\n",
        "    if model_type == 'Invariant':\n",
        "        numTerms = 12\n",
        "    elif model_type == 'Stretch':\n",
        "        numTerms = 16  # change if change range\n",
        "    cmap = plt.cm.get_cmap('jet_r', numTerms)  # define the colormap with the number of terms from the full network\n",
        "    # this way, we can use 1 or 2 term models and have the colors be the same for those terms\n",
        "    cmaplist = [cmap(i) for i in range(cmap.N)]\n",
        "    ax.tick_params('y', labelsize=16)\n",
        "    ax.tick_params('x', labelsize=16)\n",
        "    color_map(ax, lam_ut, model_UT, model_weights, Psi_model, cmaplist, terms, model_type)\n",
        "    ax.scatter(lam_ut, P_ut, s=200, zorder=103, lw=3, facecolors='w', edgecolors='k', clip_on=False)\n",
        "    plt.xlabel('Stretch (-)', fontsize=18)\n",
        "    plt.ylabel('Stress (MPa)', fontsize=18)\n",
        "    plt.tight_layout(pad=2)\n",
        "    plt.savefig(path2saveResults + '/Section_1' + 'Train'+ modelFit_mode + '_' + 'Region' + Region + '.pdf')\n",
        "    plt.close();\n",
        "\n",
        "def plotMapCom(ax, Psi_model, model_weights, model_UT, terms, lam_ut, P_ut, Region, path2saveResults, modelFit_mode, model_type):\n",
        "    if model_type == 'Invariant':\n",
        "        numTerms = 12\n",
        "    elif model_type == 'Stretch':\n",
        "        numTerms = 16  # change if change range\n",
        "    cmap = plt.cm.get_cmap('jet_r', numTerms)  # define the colormap with the number of terms from the full network\n",
        "    cmaplist = [cmap(i) for i in range(cmap.N)]\n",
        "    ax.tick_params('y', labelsize=16)\n",
        "    ax.tick_params('x', labelsize=16)\n",
        "    color_map(ax, lam_ut, model_UT, model_weights, Psi_model, cmaplist, terms, model_type)\n",
        "    ax.scatter(lam_ut, P_ut, s=800, zorder=103, lw=3, facecolors='w', edgecolors='k', clip_on=False)\n",
        "    plt.xlabel('Stretch (-)', fontsize=18)\n",
        "    plt.ylabel('Stress (MPa)', fontsize=18)\n",
        "    plt.tight_layout(pad=2)\n",
        "    plt.savefig(path2saveResults + '/Section_2' + 'Train'+ modelFit_mode + '_' + 'Region' + Region + '.pdf')\n",
        "    plt.close();\n"
      ],
      "metadata": {
        "id": "Tt5Fokjg4ags"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 6. Model Training\n",
        "\n",
        "Parameters and definitions for the model training. Try changing the number of epochs and toggling between the invariant and principal-stretch-based model. Make sure to rename the model_type variable for each test."
      ],
      "metadata": {
        "id": "qVRbZjO_4jBw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train = False\n",
        "epochs = 5000 # try 5,000-20,000 epochs for a good fit\n",
        "batch_size = 8\n",
        "folder_name = 'ME233_W25' # name the folder for your results\n",
        "\n",
        "### Choose regularization type & penalty amount\n",
        "# Option: 'L1', 'L2'\n",
        "reg = 'L1'\n",
        "pen = 0.00001  # Use 0 for no regularization\n",
        "\n",
        "### Choose which model type to build CANN architecture with\n",
        "# Options: 'Stretch', 'Invariant'\n",
        "# 'Stretch' is principal-stretch-based and contains stretches raised to fixed powers (range & number of terms can be adjusted)\n",
        "# 'Invariant' is invariant-based and contains I2, I2, I1^2, I2^2 and all with exp() and ln() activations\n",
        "model_type = 'Stretch'\n",
        "\n",
        "### Choose which loading modes to train with\n",
        "# Options: 'T', 'C', 'SS', 'TC_and_SS' (tension, compression, simple shear, tension/compression & simple shear)\n",
        "modelFit_mode_all = ['T']\n",
        "\n",
        "### Choose which types of artificial meat to train with\n",
        "# Options: 'CC', 'CX', 'BG', 'CR'\n",
        "Region_all = ['CX']\n",
        "################################################\n",
        "\n",
        "path2saveResults_0 = path + 'L1 0.00001 Section 1(1 to 2) to predit section 2 (2 to 3)/'+filename+'/'+folder_name\n",
        "makeDIR(path2saveResults_0)\n",
        "\n",
        "Model_summary = path2saveResults_0 + '/Model_summary.txt'"
      ],
      "metadata": {
        "id": "lqeeGfNH4iNq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# for w in model_weights_0:\n",
        "#   for i in w:\n",
        "#     print(i)\n",
        "\n",
        "# print(len(model_weights_0))\n",
        "print(terms)"
      ],
      "metadata": {
        "id": "3e71IrCxdktI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# #  Training and validation loop\n",
        "count = 1\n",
        "for id1, Region in enumerate(Region_all): # loop through brain region data\n",
        "\n",
        "    #R2_all_Regions = []\n",
        "    for id2, modelFit_mode in enumerate(modelFit_mode_all): # loop through model training modes\n",
        "\n",
        "        print(40*'=')\n",
        "        print(\"Comp {:d} / {:d}\".format(count, len(Region_all)*len(modelFit_mode_all)))\n",
        "        print(40*'=')\n",
        "        print(\"Region: \", Region ,\"| Fitting Mode: \", modelFit_mode)\n",
        "        print(40*'=')\n",
        "        count += 1\n",
        "\n",
        "        path2saveResults = os.path.join(path2saveResults_0,Region, modelFit_mode)\n",
        "        path2saveResults_check = os.path.join(path2saveResults,'Checkpoints')\n",
        "        makeDIR(path2saveResults)\n",
        "        makeDIR(path2saveResults_check)\n",
        "\n",
        "        P_ut, lam_ut = getStressStrain(Region) # stress/stretch/shear pairs\n",
        "\n",
        "        # Model selection\n",
        "        if model_type == 'Invariant':\n",
        "            Psi_model, terms = StrainEnergyCANN_invariant(reg, pen) # build invariant-based model\n",
        "        elif model_type == 'Stretch':\n",
        "            Psi_model, terms = StrainEnergyCANN_stretch(reg, pen) # build principle-stretch-based model\n",
        "        model_UT, Psi_model, model = modelArchitecture(Psi_model) # build uniaxial and shear models\n",
        "\n",
        "\n",
        "        with open(Model_summary,'w') as fh:\n",
        "            # Pass the file handle in as a lambda function to make it callable\n",
        "            Psi_model.summary(line_length=80, print_fn=lambda x: fh.write(x + '\\n')) # summarize layers in architecture\n",
        "\n",
        "        #%%  Model training\n",
        "        model_given, input_train, output_train, sample_weights = traindata(modelFit_mode) # model type, input/output pairs\n",
        "\n",
        "\n",
        "        Save_path = path2saveResults + '/model.h5'\n",
        "        Save_weights = path2saveResults + '/weights'\n",
        "        path_checkpoint = path2saveResults_check + '/best_weights'\n",
        "        if train: # use compile/fit parameters to train specific model (UT, SS, both) with specific input/output pairs\n",
        "            model_given, history = Compile_and_fit(model_given, input_train, output_train, epochs, path_checkpoint, sample_weights)\n",
        "\n",
        "            model_given.load_weights(path_checkpoint, by_name=False, skip_mismatch=False) # load the weights saved in the path (the best ones)\n",
        "            tf.keras.models.save_model(Psi_model, Save_path, overwrite=True) # save the model\n",
        "            Psi_model.save_weights(Save_weights, overwrite=True) # save the weights\n",
        "\n",
        "            # Plot loss function\n",
        "            loss_history = history.history['loss']\n",
        "            fig, axe = plt.subplots(figsize=[6, 5])  # inches\n",
        "            plotLoss(axe, loss_history)\n",
        "            plt.savefig(path2saveResults+'/Plot_loss_'+Region+'_'+modelFit_mode+'.pdf')\n",
        "            plt.show()\n",
        "            #plt.close()\n",
        "\n",
        "        else: # if already trained, just load the saved weights\n",
        "            Psi_model.load_weights(Save_weights, by_name=False, skip_mismatch=False)\n",
        "\n",
        "\n",
        "        # Get CANN model response\n",
        "        Stress_predict_UT = model_UT.predict(lam_ut, verbose=0)\n",
        "\n",
        "        # Show weights (remember: weights are output in the order they are built)\n",
        "        if model_type == 'Invariant':\n",
        "            weight_matrix = np.empty((terms, 1))\n",
        "            for i in range(terms):\n",
        "                value = Psi_model.get_weights()[i]\n",
        "                weight_matrix[i] = value\n",
        "            print(\"weight_matrix\")\n",
        "            print(*weight_matrix, sep=\"\\n\")\n",
        "\n",
        "        elif model_type == 'Stretch':\n",
        "            weight_matrix = np.empty((terms, 2))\n",
        "            for i in range(terms):\n",
        "                value = Psi_model.get_weights()[i][0][0]\n",
        "                weight_matrix[i, 0] = value # inner layer is first column\n",
        "            weight_matrix[:, 1] = Psi_model.get_layer('wx2').get_weights()[0].flatten() # outer layer is second column\n",
        "            print(\"weight_matrix\")\n",
        "            print(weight_matrix)\n",
        "\n",
        "        # Get the trained weights\n",
        "        model_weights_0 = Psi_model.get_weights()\n",
        "\n",
        "        # Plot the contributions of each term to the output of the model\n",
        "        fig, ax = plt.subplots(figsize=(12.5, 8.33))\n",
        "        plotMapTen(ax, Psi_model, model_weights_0, model_UT, terms, lam_ut[:3239], P_ut[:3239], Region,\n",
        "                           path2saveResults, modelFit_mode, model_type)\n",
        "        fig2, ax2 = plt.subplots(figsize=(12.5, 8.33))\n",
        "        plotMapCom(ax2, Psi_model, model_weights_0, model_UT, terms, lam_ut[3240:], P_ut[3240:], Region,\n",
        "                           path2saveResults, modelFit_mode, model_type)\n",
        "        R2_section1 = r2_score(P_ut[:3239], Stress_predict_UT[:3239])\n",
        "        R2_section2 = r2_score(P_ut[3240:], Stress_predict_UT[3240:])\n",
        "        MSE_section1 = mean_squared_error(P_ut[:3239], Stress_predict_UT[:3239])\n",
        "        MSE_section2 = mean_squared_error(P_ut[3240:], Stress_predict_UT[3240:])\n",
        "        print('R2 section1 = ', R2_section1)\n",
        "        print('R2 section2 = ', R2_section2)\n",
        "\n",
        "\n",
        "        # Save trained weights and R2 values to txt file\n",
        "        Config = {\"Region\": Region, \"modelFit_mode\": modelFit_mode, 'model_type': model_type, 'Reg': reg, 'Penalty': pen, \"R2_section1\": R2_section1, \"R2_section2\": R2_section2,\n",
        "                  \"MSE_section1\": MSE_section1, \"MSE_section2\": MSE_section2, \"weights\": weight_matrix.tolist()}\n",
        "        json.dump(Config, open(path2saveResults + \"/Config_file.txt\", 'w'))\n"
      ],
      "metadata": {
        "id": "qYkzZBq_PG1r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.scatter(lam_ut, P_ut)\n",
        "plt.scatter(lam_ut, Stress_predict_UT)\n",
        "plt.legend(['Data', 'Model Prediction'])\n",
        "plt.xlabel('Stretch (-)')\n",
        "plt.ylabel('Stress (MPa)')"
      ],
      "metadata": {
        "id": "jp50Q4xMrIi1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pbPm_kF0zL6n"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}